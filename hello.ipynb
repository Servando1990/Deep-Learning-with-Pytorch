{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feeding images into neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "hello\n1.4.0\n"
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "print ('hello')\n",
    "print (torch.version.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import imageio\n",
    "torch.set_printoptions(edgeitems=2, threshold=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (<ipython-input-12-f0d35154b096>, line 1)",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-12-f0d35154b096>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    PanS = r\"E:\\Servando\\Data\\Space-net\\AOI_4_Shanghai_Train\\MUL-PanSharpen\\\"\u001b[0m\n\u001b[1;37m                                                                             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "PanS = r\"E:\\Servando\\Data\\Space-net\\AOI_4_Shanghai_Train\\MUL-PanSharpen\\\"\n",
    "Pan = r'E:\\Servando\\Data\\Space-net\\AOI_4_Shanghai_Train\\PAN\\'\n",
    "RGBPanSharpen = r'E:\\Servando\\Data\\Space-net\\AOI_4_Shanghai_Train\\RGB-PanSharpen\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_tiff = imageio.imread(r'E:\\Servando\\Data\\Space-net\\AOI_4_Shanghai_Train\\MUL\\MUL_AOI_4_Shanghai_img3.tif')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(163, 163, 8)"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "i_tiff.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_tiff_pans = imageio.imread(r'E:\\Servando\\Data\\Space-net\\AOI_4_Shanghai_Train\\MUL-PanSharpen\\MUL-PanSharpen_AOI_4_Shanghai_img3.tif')\n",
    "#i_tiff_pan = imageio.imread(r'E:\\Servando\\Data\\Space-net\\AOI_4_Shanghai_Train\\PAN\\PAN_AOI_4_Shanghai_img3.tif')\n",
    "#i_tiff_rgbpan = imageio.imread(r'E:\\Servando\\Data\\Space-net\\AOI_4_Shanghai_Train\\RGB-PanSharpen\\PanSharpen_AOI_4_Shanghai_img3.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_tiff_pan = imageio.imread(r'E:\\Servando\\Data\\Space-net\\AOI_4_Shanghai_Train\\PAN\\PAN_AOI_4_Shanghai_img3.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_tiff_rgbpan = imageio.imread(r'E:\\Servando\\Data\\Space-net\\AOI_4_Shanghai_Train\\RGB-PanSharpen\\RGB-PanSharpen_AOI_4_Shanghai_img3.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "MUL (163, 163, 8)\nMUL-PanSharpen (650, 650, 8)\nPAN (650, 650)\nrgb (650, 650, 3)\n"
    }
   ],
   "source": [
    "print('MUL', i_tiff.shape)\n",
    "print('MUL-PanSharpen', i_tiff_pans.shape)\n",
    "print('PAN', i_tiff_pan.shape)\n",
    "print('rgb',i_tiff_rgbpan.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_tiff= i_tiff.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(163, 163, 8)"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "i_tiff.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_tiff_img = torch.from_numpy(i_tiff)\n",
    "#i_tiff_out = i_tiff.permute(2,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_tiff_out = i_tiff_img.permute(2,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "torch.Size([8, 163, 163])"
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "i_tiff_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "data_dir = 'E:\\\\Servando\\\\Data\\\\Space-net\\\\AOI_4_Shanghai_Train\\\\TEST'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 3\n",
    "batch = torch.zeros(batch_size, 3, 163, 163, dtype=torch.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "index 3 is out of bounds for dimension 0 with size 3",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-bc972f11a943>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m#print(img_t[0].shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mimg_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg_t\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# <1>\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg_t\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: index 3 is out of bounds for dimension 0 with size 3"
     ]
    }
   ],
   "source": [
    "\n",
    "filenames = [name for name in os.listdir(data_dir) if os.path.splitext(name)[-1] == '.tif']\n",
    "for i, filename in enumerate(filenames):\n",
    "    img_arr = imageio.imread(os.path.join(data_dir, filename))\n",
    "    img_arr= img_arr.astype(float)\n",
    "    img_t = torch.from_numpy(img_arr)\n",
    "    img_t = img_t.permute(2, 0, 1)\n",
    "    #print(img_t[0].shape)\n",
    "    img_t = img_t[:3] # <1>\n",
    "    batch[i] = img_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Number of batches -> 3\n"
    }
   ],
   "source": [
    "print('Number of batches ->',len(batch))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "torch.Size([3, 163, 163])\ntorch.Size([3, 163, 163])\ntorch.Size([3, 163, 163])\n3\n"
    }
   ],
   "source": [
    "print(batch[0].shape)\n",
    "print(batch[1].shape)\n",
    "print(batch[2].shape)\n",
    "print(batch.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = batch.float()\n",
    "batch /= 255.0 # normalization divide the values of picels by 255 (the maximum represenatble number in 8-but unsigned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, we normalize just a single image because we do not know yet how to operate on an entire dataset. It is good practice to compute the mean and standard deviation on the entire training data in advance and then subtract and divide by these fixed pre-computed quantities.\n",
    "\n",
    "n_channels = batch.shape[1]\n",
    "for c in range(n_channels):\n",
    "    mean = torch.mean(batch[:, c])\n",
    "    std = torch.std(batch[:, c])\n",
    "    batch[:, c] = (batch[:, c] - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "torch.Size([3, 3, 163, 163])"
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37064bitfootprintsconda81beb1dead8d4dda9419a14baedbe042",
   "display_name": "Python 3.7.0 64-bit ('footprints': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}